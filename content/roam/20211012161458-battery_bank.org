:PROPERTIES:
:ID:       b2f068c3-a99a-4493-af4e-8f2762d9cb94
:END:
#+title: battery bank
[[./20210831171810-battery.org][battery]]

* [[./20211012161557-battery_aging_model.org][battery aging model]]
* [[./20211012161635-bms_interface.org][BMS interface]]
* Algorithms
** forcasting
** outlier detection
** anomaly detection in time series
*** https://neptune.ai/blog/anomaly-detection-in-time-series
**** STL deomposition seasonal, trend and residue
**** detection using forecasting
**** classification and regression tree (CART)
*** https://towardsdatascience.com/time-series-anomaly-detection-with-pycaret-706a6e2b2427
* Modules
** https://github.com/pycaret/pycaret/tree/master/examples
** https://github.com/facebookresearch/Kats
*** forcast
** https://github.com/pycaret/pycaret
* Methods
** preprocessing: torque requrest & battery response decomposition
*** SARIMA:
**** https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/
**** https://medium.com/@kfoofw/seasonal-lags-sarima-model-fa671a858729
*** Prophet: https://facebook.github.io/prophet/#:~:text=Prophet%20is%20a%20procedure%20for,daily%20seasonality%2C%20plus%20holiday%20effects.&text=Prophet%20is%20robust%20to%20missing,and%20typically%20handles%20outliers%20well.
*** Holt-Winters
https://orangematter.solarwinds.com/2019/12/15/holt-winters-forecasting-simplified/#:~:text=Holt%2DWinters%20is%20a%20model,cyclical%20repeating%20pattern%20(seasonality).
https://otexts.com/fpp2/holt-winters.html
*** ensemble
** forecasting with Kat/PyCaret
* Project
** Fiasco/Funes
** Hail Mary/Dataphage(Astrophage)
** Nabis/Impressionist
* Retrospection
** no labels (expert knowledge) for supervised learning
** challenge and caveats for unsuperviesd learning:
*** relevant features to reflect intrinsic parameters of battery health
**** the distribution of battery health state depending on those parameters
*** when the features are relevant, sufficient *finite* data to represent this distribution
**** Example: Gaussian/uniform; GT distribution is the unknown (nonlinear, multimodal, non-stationary) natural density of data: distribution $p_{\xi}$ --> Neural Network v$p_{\theta}$
***** NN very versatile: $p_{\theta}$ can approxmate any distribution!
***** prior $p(z)$ has an impact on the final sample and capability of the whole network: $p(z) \odot p_{\theta}(x)$
***** if enough expert knowledge is available tell us it's normal distribution, just 2 parameters to estimate, still a lot of samples for bootstrapping/bagging, sample mean / sample variance, need confidence level, statistical trial for inspection.
**** scenario data (time sequences of specific scenes)
**** given the current compute resources: the way to go is to reduce the data amount requirement by defining relevant features and relevant scenarios
*** optimal architecture for G and D (optimize weights) :
**** multidimensional continuous function enough? More expertise to make this happen!
***** transformer for sequential modeling
***** make prior learnable
**** optimal hyperparameters?
*** no guarantee for convergence
*** CGAN and feature labels?
