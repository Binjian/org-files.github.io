:PROPERTIES:
:ID:       eb2233d6-db7b-428f-b6f9-d6501082381b
:END:
#+title: deep learning hardware

* Refenreces
https://geohot.github.io/blog/jekyll/update/2021/06/13/a-breakdown-of-ai-chip-companies.html

Sparsity https://www.youtube.com/watch?v=0PAiQ1jTN5k

Adi Fuchs for Accelerators https://www.youtube.com/watch?v=VQoyypYTz2U&t=1791s

cerebras https://www.youtube.com/watch?v=LiJaHflemKU https://www.youtube.com/watch?v=xnMmd2zZ3RM

Song Han http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture16.pdf

* ChipLego
** Goals
*** assessment of the design
*** application for future & current AI project
** proposal
*** Model zoo TIMM
**** different types of computer, big --> small
**** Vision model as encoder
***** ViT-pytorch (lucidrain)
***** BEiT
***** RegNet
***** ConvNext
***** FocalNet
*** Steps:
**** evaluate accessible model
**** add layers and upscale inputs to test
**** like AlexNet to adapt big models to HW
*** specs
*** design
*** NAS?
*** Generative models (Stable Diffusion model)
**** finetuning for driving world (transfer learning)
**** finetuning road and traffic related embedding
**** image2image to create inpainting for occlusion issues
**** for style transfer (get de-weathering, from 2d to 3d)
**** downscaled to improve inference, realtime training to improve the depth estimation
*** NERF
**** Large Road Model with NERF layer
***** waymo must be eyeing on this
***** compress the large nerf model to be loaded on the edge
**** query the large model as prior
*** Very strong prior knowledge/model (query the AGI)
*** High level inference with query of LLM and get the proposed high level control proprosals like Saycan
*** RegNet
*** ViT?
*** what is now?
*** what is in the future?
*** emphasis on SW 2.0
**** Any DNN model is a SW computer (turing complete), how it can be accommodated in the chip
**** LLM inference

[[./20221111125428-newrizon_proposals_for_chiplego.org][Newrizon Proposal]]

** HW & SW Co-Design
*** HW lottery!
*** algorithm
**** pruning?
**** weight sharing?
**** quantization?
**** low rank approximation?
**** winograd transformation?
*** training
*** inference
*** sparsity
*** microarchitecture
*** speedup
*** energy efficiency
*** throughput
*** parallelization
**** data
**** parameter
**** model
*** precision3
**** mixed
**** b-float16
*** Federated Learning?
* Evaluation
** Xilinx board
** BSP package Linux
** remote debugging
* Chiplego
** Jonas
*** AI 相关软件，
*** NPU 相关
*** 工具链底层 firmware
*** reference design
** William:黄虎城
*** middle 相关，非 AI specific
** John Leng:冷强
*** 所有软件交付
*** BSP， linux, qnx
*** 集成
*** stream pipeline 304，工具链
** 邹昊
*** PM, support william
** Glenn:
*** ADAS，
*** pipeline 工具，debug，
** 适合何种应用？
*** toy project
**** 便于剪裁
**** 丰富的架构
***** 编解码 VAE
***** convolution
***** Transformer ViT?
**** 深度学习计算，视频处理
*** NPU 为中心！
*** 目前的应用？
*** Linux/QNX:
**** middleware 及以上保持相同
*** 未来导向？
** 何种选择?什么后果?
** 计划：
*** NPU+AI 介绍（下周五）
SCHEDULED: <2022-10-28 周五>
*** 工具链介绍
[[./20221027095918-chiplego_demo_intro.org][ChipLego Demo Intro]]
* Assessment
** Hardware
** Software, Toolchain
** FAE Handson
*** strongly dependent on Xilinx toolchain
*** not catching up with updates not support v2.5, only v2.0
** Features very old architecture
*** not supporting transformer
*** far behind research
