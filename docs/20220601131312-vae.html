<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>VAE</title>
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">VAE</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org3db3e09">Way of VAE</a>
<ul>
<li><a href="#org7eb6c23">maximum likelihood of the data distribution, with latent space of a minimal prior information</a>
<ul>
<li><a href="#org89c67d6">KL-divergence is indirect</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org732b2dd">property</a>
<ul>
<li><a href="#orgb6274cf">prioar \(p(z)\) has an impact, Gaussiana as prior has the maximal entropy and thus minimizaion of the prior information.</a></li>
<li><a href="#org5f199d9">\(p_{\theta}(z|x)\) and \(q_{\phi}(z|x)\) will be finally very simimlar thus can be ignored.</a></li>
<li><a href="#org74ccf82">encoder part use KL-Divergence, Decoder data maximum likelihood</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org3db3e09" class="outline-2">
<h2 id="org3db3e09">Way of VAE</h2>
<div class="outline-text-2" id="text-org3db3e09">
</div>
<div id="outline-container-org7eb6c23" class="outline-3">
<h3 id="org7eb6c23">maximum likelihood of the data distribution, with latent space of a minimal prior information</h3>
<div class="outline-text-3" id="text-org7eb6c23">
</div>
<div id="outline-container-org89c67d6" class="outline-4">
<h4 id="org89c67d6">KL-divergence is indirect</h4>
</div>
</div>
</div>
<div id="outline-container-org732b2dd" class="outline-2">
<h2 id="org732b2dd">property</h2>
<div class="outline-text-2" id="text-org732b2dd">
</div>
<div id="outline-container-orgb6274cf" class="outline-3">
<h3 id="orgb6274cf">prioar \(p(z)\) has an impact, Gaussiana as prior has the maximal entropy and thus minimizaion of the prior information.</h3>
</div>
<div id="outline-container-org5f199d9" class="outline-3">
<h3 id="org5f199d9">\(p_{\theta}(z|x)\) and \(q_{\phi}(z|x)\) will be finally very simimlar thus can be ignored.</h3>
</div>
<div id="outline-container-org74ccf82" class="outline-3">
<h3 id="org74ccf82">encoder part use KL-Divergence, Decoder data maximum likelihood</h3>
<div class="outline-text-3" id="text-org74ccf82">
<p>
<a href="./20211221093832-gan.html">GAN</a>
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="creator"><a href="https://www.gnu.org/software/emacs/">Emacs</a> 30.0.50 (<a href="https://orgmode.org">Org</a> mode 9.6.7)</p>
</div>
</body>
</html>