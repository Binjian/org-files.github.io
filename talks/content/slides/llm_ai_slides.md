+++
title = "å¤§å‹è¯­è¨€æ¨¡å‹ä¸äººå·¥æ™ºèƒ½"
author = ["å¿»æ–Œå¥"]
date = 2023-03-13T00:00:00+08:00
draft = false
+++

<div class="ox-hugo-toc toc">

<div class="heading">Table of Contents</div>

- [æ¦‚è¿°](#æ¦‚è¿°)
- [å¤§å‹è¯­è¨€æ¨¡å‹çš„å·¥ç¨‹å®ç°](#å¤§å‹è¯­è¨€æ¨¡å‹çš„å·¥ç¨‹å®ç°)
- [å±•æœ›å’ŒæŒ‘æˆ˜](#å±•æœ›å’ŒæŒ‘æˆ˜)

</div>
<!--endtoc-->



## æ¦‚è¿° {#æ¦‚è¿°}


### æŠ€æœ¯è¿›æ­¥ {#æŠ€æœ¯è¿›æ­¥}

{{< figure src="/ox-hugo/technology.png" >}}

<div class="NOTES">

æ–°æŠ€æœ¯çš„å‡ºç°å¯¼è‡´ç¤¾ä¼šçš„è¿›æ­¥ï¼Œäººå·¥æ™ºèƒ½è¢«èª‰ä¸ºæ–°æ—¶ä»£çš„ç”µåŠ›
ç”µåŠ›æœ‰åå¤„ï¼š

-   è§¦ç”µå±é™©
-   åŸºç¡€è®¾æ–½æ˜‚è´µ
-   æ¶ˆç­æ—§çš„è¡Œä¸š,äº§ç”Ÿæ–°çš„è¡Œä¸šå’ŒèŒä¸š

å¤§æ•°æ®ï¼š
[Jordan Tigani (ex Google Enguineering lead of BigQuery)å¤§æ•°æ®å·²æ­»](https://motherduck.com/blog/big-data-is-dead/)
2011, 2017~2019,å¤§æ•°æ®å¹¶æ²¡æœ‰æˆä¸ºç“¶é¢ˆ

-   åˆ°ä¸äº†å¤§æ•°æ®çº§åˆ« GB
-   å­˜å‚¨å’Œè®¡ç®—æ­£åœ¨åˆ†ç¦»
-   æ²¡æœ‰æ–°ä¸šåŠ¡ï¼Œæ•°æ®æ˜¯çº¿æ€§å¢é•¿çš„
-   äººä»¬åªå…³å¿ƒæœ€è¿‘çš„æ•°æ®
-   çœŸæ­£æœ‰å¤§æ•°æ®çš„å…¬å¸ï¼Œå‡ ä¹ä»ä¸æŸ¥è¯¢å…¨éƒ¨æ•°æ®, 2017
-   å•æœºçš„è®¡ç®—èƒ½åŠ›å¤§å¢

</div>


### ç§‘å­¦è§‚å¿µçš„æ›´æ–° {#ç§‘å­¦è§‚å¿µçš„æ›´æ–°}

{{< figure src="/ox-hugo/science.png" >}}

<div class="NOTES">

ä¸‰ä¸ªé¢†åŸŸå‘ç”Ÿå·¨å¤§æŒä¹…å’Œæ·±åˆ»çš„å˜åŒ–

-   ç†è§£åŸç†è¶Šæ·±åˆ»ï¼Œåº”ç”¨å½±å“è¶Šå¤§ï¼Œ--&gt; é©å‘½æ€§çš„åº”ç”¨
    -   ç‰©ç†å­¦æ¡ˆä¾‹ï¼šæ ¸èšå˜ï¼Œå®‡å®™çš„èµ·æºï¼Œæ’æ˜Ÿçš„å½¢æˆï¼Œ\\(E=MC^2\\) ï¼Œå–ä¹‹ä¸å°½ç”¨ä¹‹ä¸ç«­çš„å®‰å…¨èƒ½æºï¼Œ50 å¹´ä»¥å--&gt;5 å¹´ä»¥å
    -   ç”Ÿç‰©å­¦æ¡ˆä¾‹ï¼šçœŸæ ¸ç»†èƒç”Ÿç‰©çš„ç”ŸåŒ–èµ·æºï¼šå…‰åˆä½œç”¨ï¼Œç»†èƒå‘¼å¸ä½œç”¨ï¼Œçº¿ç²’ä½“ï¼Œå¤–æ˜Ÿç”Ÿå‘½ç ”ç©¶
-   å‘ç°é—®é¢˜æ˜¯å–å¾—è¿›å±•çš„ç ”ç©¶æ–¹å‘ã€‚
-   æ·±åˆ»ç†è§£ä¼šæ”¹å˜è§‚å¿µï¼

[æ¯”å°”ç›–èŒ¨ AIçš„æ—¶ä»£å¼€å§‹äº†](https://www.gatesnotes.com/The-Age-of-AI-Has-Begun)

-   GUI ä¹‹åçš„ç¬¬äºŒæ¬¡é©å‘½æ€§çš„æŠ€æœ¯å±•ç¤º 2022.ä¸­æ—¬--&gt; 9 æœˆ

</div>


#### ä»€ä¹ˆæ˜¯ ChatGPTï¼Ÿ {#ä»€ä¹ˆæ˜¯-chatgpt}

<b><u>Chat</u></b> <b><u>G</u></b>enerative <b><u>P</u></b>retrained <b><u>T</u></b>ransformer

-   æœ¬è´¨ï¼šæ™ºèƒ½è½¬åŒ–ä¸ºè®¡ç®—
    -   è®¡ç®—çš„åŸºæœ¬å¯¹è±¡ï¼šå†…åµŒç©ºé—´ ï¼ˆ **embedding** ï¼‰
    -   æœºå™¨å­¦ä¹ æ–¹æ³•
-   ç‰¹ç‚¹
    -   å¤§è§„æ¨¡
    -   å•ä¸€çš„æ–¹æ³•ï¼ˆæ·±åº¦å­¦ä¹  Transformer æ¶æ„ï¼‰
    -   å¤šè¯­è¨€æ¨¡å¼
    -   å¼ºäººå·¥æ™ºèƒ½ï¼ŒAGIï¼ˆï¼Ÿï¼‰
-   å¼€æºå¼€æ”¾
    -   çŸ¥é“å¦‚ä½•å·¥ç¨‹å®ç°ï¼Œæ ¹æœ¬åŸå› ä¸æ¸…æ¥š
    -   æ™®éé€‚ç”¨å…¶ä»–å¤æ‚ç°è±¡ï¼šå›¾åƒï¼Œæ§åˆ¶ï¼Œå¯è¿ç§»
    -   æœºç¼˜å·§åˆ

<div class="NOTES">

-   è¯­æ–™ï¼Œè®­ç»ƒæ ·æœ¬
    -   until 2003 5 EB ExaByte, 2013 5EB/2 days (1EB = \\(10^9\\) GB, 1 Zettabye = \\(10^{12}\\) GB, billions and billions Carl Sagan)
    -   æ¨¡å‹ï¼Œ è®¡ç®—é‡
    -   è®­ç»ƒä¸å……åˆ†
    -   è§„æ¨¡åŒ–çš„å¿…è¦çš„ï¼Œä½†å¾ˆå¯èƒ½ä¸æ˜¯å……åˆ†çš„
-   å•ä¸€çš„æ–¹æ³•ï¼ˆäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ ï¼Œæ·±åº¦å­¦ä¹ ï¼Œå¤§å‹ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œ è®¡ç®—æ¨¡å‹ï¼‰ï¼š1990s å°±æœ‰ï¼Œè®¡ç®—é‡ï¼Œäº’è”ç½‘çš„å…´èµ·
    -   å·¥ç¨‹å®ç°åŸç†å®Œå…¨æ¸…æ¥šï¼Œç»“æœéœ€è¦è§£é‡Šå’Œåˆ†æï¼Œæœ‰äº‰è®®
    -   èµŒæ³¨ï¼Œstakeï¼Œè‡ªä¿¡ï¼Œå‹‡æ°”ï¼Œä¿¡ä»°
-   å¶ç„¶ Serendipity
    -   ç¡¬ä»¶å½©ç¥¨ GPU
        -   1990 64 ä¸ªèŠ‚ç‚¹çš„è®¡ç®—æœºç½‘ç»œï¼Œjeff dean, Yoshua Bengio
    -   ä¸“å®¶ï¼šæé£é£, Hinton, Bengio, LeCunn
    -   å¶ç„¶ä¸­çš„å¿…ç„¶ï¼šç”Ÿå‘½çš„ç”ŸåŒ–èµ·æºï¼ŒçœŸæ ¸ç”Ÿç‰©çš„èµ·æºï¼Œè¯­è¨€çš„èµ·æºï¼ˆ20 ä¸‡å¹´å‰ï¼‰; æ¼”åŒ–æ¨åŠ¨æŒ‡æ•°çº§å¢é•¿
-   å·¥ç¨‹å®ç°ç†è§£
    -   å¯è§†åŒ–ï¼ŒåŠ¨ç”»çš„æ–¹å¼ï¼ˆJay Alammar, Lilian Weng, Christopher Pottsï¼‰
    -   å‰¥æ´‹è‘±çš„æ–¹å¼ï¼Œä¸€å±‚å±‚å¾€é‡Œçœ‹

</div>


#### Ilya Sutskever NIPS 2015 {#ilya-sutskever-nips-2015}

{{< figure src="/ox-hugo/sutskever_nips2015.png" title="Sutskever 2015" width="400pix" >}}

> -   å¦‚æœæ•°æ®é›†å¤Ÿå¤§
> -   å¹¶ä¸”è®­ç»ƒä¸€ä¸ªå¾ˆå¤§çš„ç¥ç»ç½‘ç»œ
> -   ä½ è‚¯å®šèƒ½æˆåŠŸ!

<div class="NOTES">

RNN æ¨¡å‹ï¼Œè°·æ­Œå¤§è„‘
<https://www.youtube.com/watch?v=-uyXE7dY5H0>

</div>


#### å¤§å‹è¯­è¨€æ¨¡å‹ {#å¤§å‹è¯­è¨€æ¨¡å‹}

<!--list-separator-->

-  GPT ç³»åˆ—

    <!--list-separator-->

    -  GPT2 (1.5B), GPT3 (175B), InstructGPT(Alignment, RLHF)ï¼Œ ChatGPT(æ•°æ®æ”¶é›†å·®å¼‚), GPT4(?)

        ğŸ‘‰ NanoGPT (Andrej Karpathy)

        -   [ChatGPT for Slack](https://www.salesforce.com/news/wp-content/uploads/sites/3/2023/03/Slack_ChatGPT_Blue.gif)

        {{< figure src="/ox-hugo/Slack_ChatGPT_Blue.gif" title="ç¥ç»ç½‘ç»œåšä¸ºå¤§å‹è¯­è¨€æ¨¡å‹" width="600px" >}}


#### å¤§å‹è¯­è¨€æ¨¡å‹åŠè®­ç»ƒè®¡ç®—é‡ {#å¤§å‹è¯­è¨€æ¨¡å‹åŠè®­ç»ƒè®¡ç®—é‡}

{{< figure src="/ox-hugo/Ai-training-computation.png" title="éšç©ºé—´èšç±»åˆ†å¸ƒ" width="500pix" >}}

-   Google: LaMDA(137B),PaLM(540B, Minerva,PaLM-E),BERT(0.34B)
-   Meta: Galactica,OPT(175B),LLaMAï¼ˆ65Bï¼‰
-   MS&amp;NV: Megatron(530B)
-   DM: **Chinchilla** (70B)
-   HFğŸ¤—:Bloom(175B)
-   EleutherAI: GPT-NEO(2.7B),-J(6B),-NeoX(20B)
-   DALL-E, Imagen, Flamingo, Parti, SD

<div class="NOTES">

æ¨¡å‹å¤§å°ï¼šç¥ç»ç½‘ç»œå‚æ•°ä¸ªæ•°ï¼ˆæ¨ç†ï¼‰ï¼Œè®­ç»ƒæ¶ˆè€—çš„è®¡ç®—é‡

è®¡ç®—é—®é¢˜ï¼

kiloFlops 10^3, metaFlops 10^6, giga- 10^9ï¼ˆåäº¿ï¼‰, tera- 10^12(ä¸‡äº¿), peta- 10^15ï¼ˆåƒä¸‡äº¿ï¼‰, exa- 10^18ï¼ˆç™¾ä¸‡ä¸‡äº¿ï¼Œç™¾äº¿äº¿, zetta- 10^21ï¼ˆä¸‡ä¸‡ä¸‡äº¿ï¼‰, yotta- 10^24, ronna- 10^27, quetta-10^30

Palm Pathway Languane model, -e embodied, open API ï¼ˆ3.14ï¼‰
Chinchilla æ¨¡å‹å’Œæ„ä¹‰ï¼š æ‰€æœ‰çš„æ¨¡å‹ï¼šè®­ç»ƒä¸è¶³ï¼Œæ¨¡å‹å¤ªå¤§, undertrained
Amazon: AlexaTM(20B)

</div>


#### é”‚ç”µæ± èƒ½é‡å¯†åº¦æå‡ {#é”‚ç”µæ± èƒ½é‡å¯†åº¦æå‡}

{{< figure src="/ox-hugo/FOTW_1234.png" title="é”‚ç”µæ± èƒ½é‡å¯†åº¦çš„å¢é•¿" width="800px" >}}


#### å¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›æ”¹å–„ {#å¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›æ”¹å–„}

{{< figure src="/ox-hugo/llm-progress.jpg" title="Emergence Behavior" width="500px" >}}

<div class="NOTES">

2012 AlexNet(PC)
2017 Transformer(Attention)
çˆ†ç‚¸æ€§å‘å±•

</div>


#### ç¤¾ä¼šå½±å“ {#ç¤¾ä¼šå½±å“}

{{< figure src="/ox-hugo/ai_investment.png" alt="äººå·¥æ™ºèƒ½çš„æŠ•å…¥" title="äººå·¥æ™ºèƒ½çš„æŠ•å…¥" width="600px" >}}

-   å¾®è½¯å…¥è‚¡ OpenAI 100 äº¿ç¾å…ƒï¼ŒæŒè‚¡å¢è‡³ 49%ï¼Œ
-   äººå·¥æ™ºèƒ½å†›å¤‡ç«èµ›ï¼šå¾®è½¯(Sydney)ï¼Œè°·æ­Œ(LLaMDA, Bard)ï¼ŒMeta(Galactica, LlaMa), GPT4 å‘å¸ƒ
-   æ™ºèƒ½(Intelligence)ï¼Œèƒ½åŠ¨æ€§(Agency)ï¼ŒçŸ¥è§‰ï¼ˆSentience)ï¼Œæ„è¯†(Conciousness)ï¼Œæ„å¿—ï¼ˆFree Will)...
    -   [Washington Post LaMDA Report](https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/)

<div class="NOTES">

-   å¤æ—¦é‚±é”¡é¹ MOSS
-   æ™ºèƒ½çš„ç‰©è´¨åŸºç¡€?
-   æ™ºèƒ½æ˜¯äººæ€§æ ¹æœ¬æ€§çš„ä¸€éƒ¨åˆ†ï¼Ÿï¼ˆä»äººæ€§ä¸­åˆ†ç¦»ï¼Ÿï¼‰
-   é»„æ˜“å±± Yishan Wong,å‰ reddit CEO(2012-2014) é¢„è¨€ 2023 å¹´åº•ä¼šå‘ç”ŸæŸä¸ªå¥‡ç‚¹äº‹ä»¶ï¼

</div>


#### [ChatGPTçš„è™šå‡æ‰¿è¯º](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html) {#chatgptçš„è™šå‡æ‰¿è¯º}

{{< figure src="/ox-hugo/Noam_Chomsky_portrait_2017_retouched.png" title="è¯ºå§†â‹…ä¹”å§†æ–¯åŸº" width="400pix" >}}

> æ‰€è°“äººå·¥æ™ºèƒ½é©å‘½æ€§çš„è¿›å±•ä»¤äººæ—¢æ‹…å¿§åˆä¹è§‚ã€‚
> ä¹è§‚æ˜¯å› ä¸ºæ™ºèƒ½å¯ä»¥ç”¨äºè§£å†³é—®é¢˜ï¼Œæ‹…å¿§æ˜¯å› ä¸ºå½“ä»Šæœ€æµè¡Œçš„äººå·¥æ™ºèƒ½æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯æœºå™¨å­¦ä¹ ï¼Œå®ƒçš„è¯­è¨€å’ŒçŸ¥è¯†çš„æ¦‚å¿µä»æ ¹æœ¬ä¸Šæ˜¯æœ‰ç¼ºé™·çš„ã€‚

<div class="NOTES">

è¿™ç§æœºå™¨å­¦ä¹ æ–¹æ³•æŠŠè¿™äº›å†…å«ç¼ºé™·çš„æ¦‚å¿µæ•´åˆåˆ°æˆ‘ä»¬çš„æŠ€æœ¯å’Œäº§å“ä¸­ï¼Œ ä»è€Œè´¬ä½äº†æˆ‘ä»¬çš„ç§‘å­¦å’Œé“å¾·ä¼¦ç†ã€‚
The human mind is not, like ChatGPT and its ilk, a lumbering statistical engine for pattern matching, gorging on hundreds of terabytes of data and extrapolating the most likely conversational response or most probable answer to a scientific question. On the contrary, the human mind is a surprisingly efficient and even elegant system that operates with small amounts of information; it seeks not to infer brute correlations among data points but to create explanations.

æ‰¹è¯„ï¼šOxford Summerfield Lab:"Like others, Chomsky pits â€œpattern matchingâ€ vs. â€œunderstandingâ€. this is a sort of neo-dualism: it diminishes computation by asserting that it lacks some intangible quality (as we might diminish other minds by assuming they lacks some intangible quality (as we might diminish other minds by assuming they lack subjectivity)

ä»ä½›æ•™è§’åº¦ï¼ŒäºŒå…ƒè®ºå¤¸å¤§â€œæˆ‘ç›¸â€ï¼Œæ‰§è¿·

</div>


#### [Yoshua Bengio](https://venturebeat.com/ai/as-gpt-4-chatter-resumes-yoshua-bengio-says-chatgpt-is-a-wake-up-call/) {#yoshua-bengio}

{{< figure src="/ox-hugo/Yoshua_Bengio_2019_cropped.jpg" title="è¯ºå§†â‹…ä¹”å§†æ–¯åŸº" width="400pix" >}}

> ChatGPT ä»¤äººå°è±¡æ·±åˆ»ï¼Œä½†åœ¨ç§‘å­¦ä¸Šåªæ˜¯å¾®å°çš„ä¸€æ­¥ï¼Œæœ€å¤šç§°å¾—ä¸Šæ˜¯å·¥ç¨‹ä¸Šçš„è¿›å±•ã€‚å®ƒçš„ä¸»è¦æ„ä¹‰åœ¨äºå”¤é†’å…¬ä¼—å¯¹äººå·¥æ™ºèƒ½æ„ä¹‰çš„è®¤è¯†ã€‚

<div class="NOTES">

-   1990sï¼š1991 "ANN and their application to sequence recognition"
-   2000sï¼š2003 "A Neural Probabilistic Language Model" ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸºç¡€ï¼
-   2010sï¼š2014 "Neural Machine Translation by Jointly Learning to Align and translate"
-   2018 å›¾çµå¥–
-   2010 å¹´ä»¥å‰ï¼Œç›¸ä¿¡è¿™ç§æ–¹æ³•èƒ½æˆåŠŸçš„å±ˆæŒ‡å¯æ•°ï¼

2000s: embedding ä»£æ›¿ n-gram n å…ƒè¯­æ³•ï¼ŒMarkov é“¾

1.  æ•°å­¦æ¨¡å‹
2.  ä¼˜åŒ–æ–¹æ³•ï¼ˆè¡¨è¾¾å’Œå®ç°æ–¹å¼ï¼‰

</div>


## å¤§å‹è¯­è¨€æ¨¡å‹çš„å·¥ç¨‹å®ç° {#å¤§å‹è¯­è¨€æ¨¡å‹çš„å·¥ç¨‹å®ç°}


### ç”¨ä¾‹ {#ç”¨ä¾‹}

{{< figure src="/ox-hugo/nn.png" title="ç¥ç»ç½‘ç»œåšä¸ºå¤§å‹è¯­è¨€æ¨¡å‹" width="500px" >}}

<div class="NOTES">

-   ç†Ÿæ‚‰çš„æ–¹æ¡ˆï¼šå›¾åƒï¼Œè¯­éŸ³ï¼Œæ§åˆ¶ï¼Œä¸‹æ£‹ï¼Œè‡ªç„¶è¯­è¨€
-   æ— è®ºè¾“å…¥æºè¿ç»­ç¦»æ•£éƒ½æ˜¯ä¸€ç§å¤„ç†æ–¹å¼ï¼šè‡ªç„¶è¯­è¨€æœ¬è´¨ä¸Šæ˜¯ç¦»æ•£çš„ï¼Œå›¾åƒï¼Œè¯­éŸ³å’Œæ§åˆ¶ç­–ç•¥æœ¬è´¨ä¸Šæ˜¯è¿ç»­çš„ã€‚ï¼ˆï¼Ÿï¼‰
-   å¤šå±‚æ„ŸçŸ¥æœºæ˜¯æœ€å¹¿ä¹‰çš„ç¥ç»ç½‘ç»œï¼ŒåŒ…å«æ‰€æœ‰å…¶ä»–çš„ç½‘ç»œç±»å‹ã€‚æ–­å¼€æŸäº›è¿æ¥å³å¯ï¼Œæ¯”å¦‚å·ç§¯ç½‘
-   ä¿¡å·æ•°å­¦æ¨¡å‹+ä¿¡å·çš„å¤„ç†æ¨¡å‹ï¼ˆç½‘ç»œï¼‰

</div>


### è¯­è¨€ç¼–ç æ¨¡å‹ï¼šè¯­ç´ å’Œ n-å…ƒè¯­æ³•(n-gram) {#è¯­è¨€ç¼–ç æ¨¡å‹-è¯­ç´ å’Œ-n-å…ƒè¯­æ³•--n-gram}

{{< figure src="/ox-hugo/ngram-example.png" title="n å…ƒè¯­æ³•ï¼ˆn-gramï¼‰" width="500px" >}}

{{< figure src="/ox-hugo/ngram-model.gif" title="n å…ƒè¯­æ³•ï¼ˆn-gramï¼‰" width="500px" >}}

<div class="NOTES">

-   è¯­ç´ çš„è®¾è®¡å‚æ•°é€‰æ‹©ï¼šå­—æ¯ï¼ŒéŸ³ç´ ï¼ŒéŸ³èŠ‚ï¼Œå•è¯ï¼Œ
-   ç»Ÿè®¡æ–¹æ³•ä¼˜åŒ–é€‰æ‹©ï¼ˆæ— ç›‘ç£å­¦ä¹ ï¼ŒByte-Pair-Encodingï¼‰ï¼šgoogle sentencepiece; openai tiktoken
-   é©¬å°”å¯å¤«é“¾ï¼šå¤æ‚åº¦éšç»´åº¦çš„è¯…å’’

</div>


### GPT ä¸­çš„è®¡ç®—å¯¹è±¡ï¼šå†…åµŒ(embedding) {#gpt-ä¸­çš„è®¡ç®—å¯¹è±¡-å†…åµŒ--embedding}

{{< figure src="/ox-hugo/word2vec.png" title="å†…åµŒ" width="500px" >}}

1.  å†…åµŒï¼ˆå•è¯/è¯­ç´ çš„ç¼–ç ï¼‰
    -   ç‹¬ç«‹è¯­ä¹‰ï¼Œåœ¨å¥å­/æ–‡æœ¬çš„ä¸åŒä½ç½®é‡å¤å‡ºç°ï¼Œå¯ä»¥å¤ç”¨çš„å˜é‡
    -   å¯¹åº”äºæ„Ÿè´¨ï¼ˆQuoliaï¼‰ï¼šæ¦‚å¿µï¼ˆé¢œè‰²ï¼‰åœ¨æ„è¯†ä¸­çš„èšç±»ï¼Œè¯­è¨€åªæ˜¯ä¸€ç§æ¥å£
2.  å†…åµŒçš„ç›¸äº’å…³ç³»é€šè¿‡è®¡ç®—ç¡®è®¤
3.  å†…åµŒé€šè¿‡è®­ç»ƒæ ·æœ¬å­¦ä¹ ï¼Œæ”¶é›†ç”±å¥æ³•ç¡®å®šçš„è¯­ä¹‰
4.  [é¢„è®­ç»ƒå†…åµŒç©ºé—´ï¼ˆtensorflowï¼‰](https://projector.tensorflow.org/)

<div class="NOTES">

-   å†…åµŒç©ºé—´ï¼ˆembeddingï¼‰ï¼šæ¦‚å¿µç©ºé—´ , ï¼ˆç»Ÿè®¡æ–¹æ³•ç¡®å®šçš„ï¼‰
-   å†…åµŒä¸æ˜¯è¯­ç´ ï¼Œæ˜¯å¯¹è¯­ç´ è¿›è¡Œç¼–ç å¾—åˆ°çš„ï¼Œéœ€è¦ç«¯åˆ°ç«¯è®­ç»ƒ,token ä»¤ç‰Œï¼Œçº¦ç­‰äºå•è¯ 100 token çº¦ç­‰äº 75 ä¸ªå•è¯
-   å†…åµŒå¯¹åº”äººç±»è¯­è¨€ä¸­çš„æ¦‚å¿µï¼ˆquolia æ„Ÿè´¨ï¼‰ï¼šç¦»æ•£çš„ï¼Œå¸æ”¶çš„ã€‚ï¼ˆYoshua Bengio: quolia,ç¦»æ•£ï¼Œæ¦‚å¿µç©ºé—´çš„å¼•åŠ›ä¸­å¿ƒï¼‰
-   çº¿æ€§ç»„åˆï¼Œç®€å•çš„çŸ©é˜µè¿ç®—
-   ç½‘ç»œçš„æƒé‡ç³»æ•°ï¼šçŸ©é˜µè¿ç®—çš„ç³»æ•°ï¼Œå¯¹åº”è¿™äº›æ¦‚å¿µä¹‹é—´çš„è”ç³»
-   ç¥ç»ç½‘ç»œï¼šåˆ†å¸ƒå¼è¡¨è¾¾æ¨¡å‹

</div>


### å†…åµŒçš„è¿ç®—ï¼ˆembeddingï¼‰ {#å†…åµŒçš„è¿ç®—-embedding}

{{< figure src="/ox-hugo/king-colored-embedding.png" alt="King, Man, Woman" title="å†…åµŒå‘é‡" width="800pix" >}}

{{< figure src="/ox-hugo/king-man-woman-embedding.png" title="éšç©ºé—´èšç±»åˆ†å¸ƒ" width="800pix" >}}

{{< figure src="/ox-hugo/queen-woman-girl-embeddings.png" title="éšç©ºé—´èšç±»åˆ†å¸ƒ" width="800pix" >}}

{{< figure src="/ox-hugo/king-analogy-viz.png" title="éšç©ºé—´èšç±»åˆ†å¸ƒ" width="800pix" >}}

<div class="NOTES">

æ•°æ®ï¼ˆå•è¯ï¼‰æœ¬èº«æ˜¯æœ‰ç»“æ„çš„,ç›¸äº’å…³ç³»ï¼Œå‡ºç°çš„é¢‘ç‡ï¼Œç›¸ä¼¼æ€§ï¼Œäº¤æ¢æ€§ï¼Œä½ç½®ï¼ˆè¯­æ³•ï¼Œå¥æ³•)çš„å«ä¹‰ã€‚
ç”±ç¥ç»ç½‘ç»œåˆ†å¸ƒå¼åœ°è¡¨è¾¾ï¼šæ¦‚å¿µä¹‹é—´çš„å…³ç³»ï¼Œè¿ç®—ï¼ˆç¥ç»è„‰å†²çš„ä¼ å¯¼ï¼‰
ä¸‡ç‰©éƒ½æœ‰ä¸€ç§æ¨¡å¼ï¼Œå®ƒæ˜¯æˆ‘ä»¬å®‡å®™çš„ä¸€éƒ¨åˆ†ã€‚ å®ƒå…·æœ‰å¯¹ç§°ã€ä¼˜é›…å’Œé­…åŠ›â€”â€”æ‚¨æ€»èƒ½åœ¨çœŸæ­£çš„è‰ºæœ¯å®¶æç»˜çš„ä¸œè¥¿ä¸­å‘ç°è¿™äº›å“è´¨ã€‚ ä½ å¯ä»¥åœ¨å­£èŠ‚çš„äº¤æ›¿ä¸­ï¼Œåœ¨æ²™å­æ²¿ç€å±±è„Šçš„è½¨è¿¹ä¸­ï¼Œåœ¨æ‚é…šæ²¹çŒæœ¨ä¸›çš„ææ¡ä¸›ä¸­æˆ–å®ƒçš„å¶å­çš„å›¾æ¡ˆä¸­æ‰¾åˆ°å®ƒã€‚
æˆ‘ä»¬è¯•å›¾åœ¨æˆ‘ä»¬çš„ç”Ÿæ´»å’Œç¤¾ä¼šä¸­å¤åˆ¶è¿™äº›æ¨¡å¼ï¼Œå¯»æ‰¾èŠ‚å¥ã€èˆè¹ˆå’Œä»¤äººèˆ’é€‚çš„å½¢å¼ã€‚ ç„¶è€Œï¼Œåœ¨å¯»æ‰¾ç»ˆæå®Œç¾çš„è¿‡ç¨‹ä¸­å¯èƒ½ä¼šçœ‹åˆ°å±é™©ã€‚ å¾ˆæ˜æ˜¾ï¼Œæœ€ç»ˆæ¨¡å¼åŒ…å«å®ƒè‡ªå·±çš„å›ºå®šæ€§ã€‚ åœ¨è¿™æ ·çš„å®Œç¾ä¸­ï¼Œä¸‡ç‰©éƒ½èµ°å‘æ­»äº¡ã€‚
â€œThere is in all things a pattern that is part of our universe. It has symmetry, elegance, and grace - those qualities you find always in that which the true artist captures. You can find it in the turning of the seasons, in the way sand trails along a ridge, in the branch clusters of the creosote bush or the pattern of its leaves.
We try to copy these patterns in our lives and our society, seeking the rhythms, the dances, the forms that comfort. Yet, it is possible to see peril in the finding of ultimate perfection. It is clear that the ultimate pattern contains it own fixity. In such perfection, all things move toward death.â€ ~ Dune (1965)

</div>


### å›¾åƒä¸­çš„å†…åµŒ {#å›¾åƒä¸­çš„å†…åµŒ}

{{< figure src="/ox-hugo/image_embedding.png" title="å›¾åƒå†…åµŒ" width="800px" >}}

1.  å›¾åƒå†…åµŒç¼–ç å’Œè§£ç ï¼Œé€šè¿‡ DCGAN è®­ç»ƒå¾—åˆ°
2.  å†…åµŒå‚æ•°çš„æ’å€¼ï¼šå›¾åƒçš„è¿ç»­å˜åŒ–ï¼ˆç”·--&gt;å¥³ï¼‰
3.  å†…åµŒçš„å‘é‡è¿ç®—ï¼šå›¾åƒçš„ä¿®æ”¹

<div class="NOTES">

-   Alec Radford now at OpenAI, credit for OpenAI LLM

</div>


### [GPT3 è®­ç»ƒ](https://jalammar.github.io/how-gpt3-works-visualizations-animations/) {#gpt3-è®­ç»ƒ}

{{< figure src="/ox-hugo/01-gpt3-language-model-overview.gif" alt="Overview" title="overview" width="500pix" >}}

{{< figure src="/ox-hugo/02-gpt3-training-language-model.gif" alt="training" title="Training" width="500pix" >}}

{{< figure src="/ox-hugo/gpt3-training-examples-sliding-window.png" alt="training samples" title="training samples" width="500pix" >}}

{{< figure src="/ox-hugo/03-gpt3-training-step-back-prop.gif" title="éšç©ºé—´èšç±»åˆ†å¸ƒ" width="500pix" >}}

<div class="NOTES">

1.  é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆæ–‡æœ¬
2.  å•ä¸€å¤§æ¨¡å‹è®­ç»ƒï¼š355GPU years $4.6Mï¼Œ 300 B (token, å•è¯ï¼Œè¯å¹²/è¯æ ¹ï¼‰
3.  è®­ç»ƒæ ·æœ¬ç”Ÿæˆ
4.  è®­ç»ƒï¼šé¢„æµ‹ä¸‹ä¸ªå•è¯,æ ¹æ®ç›®æ ‡ä¿®æ­£å‚æ•°ï¼ˆ175 B)
5.  æ•°æ®
    -   ç½‘ç»œæ–‡æœ¬
    -   ä»£ç 
    -   è‹±è¯­
6.  åŸºäºä¸Šä¸‹æ–‡ç†è§£çš„è®­ç»ƒ

</div>


### [GPT3 æ¨ç†](https://jalammar.github.io/how-gpt3-works-visualizations-animations/) {#gpt3-æ¨ç†}

{{< figure src="/ox-hugo/04-gpt3-generate-tokens-output.gif" alt="Overview" title="overview" width="500pix" >}}

{{< figure src="/ox-hugo/gpt3-parameters-weights.png" alt="training" title="Training" width="500pix" >}}

{{< figure src="/ox-hugo/05-gpt3-generate-output-context-window.gif" alt="training samples" title="training samples" width="500pix" >}}

{{< figure src="/ox-hugo/06-gpt3-embedding.gif" title="éšç©ºé—´èšç±»åˆ†å¸ƒ" width="500pix" >}}

<div class="NOTES">

1.  ç”Ÿæˆæ¨¡å‹(Generative):æ¨ç†ä¸€æ¬¡ç”Ÿæˆä¸€ä¸ªå•è¯;åºåˆ—ï¼Œè‡ªå›å½’æ¨¡å‹;å¯¹æ¦‚ç‡åˆ†å¸ƒçš„é‡‡æ ·,æ˜¯éšæœºçš„ã€‚å¤šæ¨¡æ€çš„æ ¹æœ¬åŸå› ã€‚
2.  æ— ç›‘ç£å­¦ä¹ é¢„è®­ç»ƒç”Ÿæˆæœ‰ç”¨çš„å‚æ•°
3.  ä¸Šä¸‹æ–‡æœ€å¤§é•¿åº¦ï¼š2048 (2k);GPT-4 0.03+0.06/1k@8k, 0.06+0.12/1k@32k; ColT5 64Kï¼Œè‡ªå›å½’æ¨¡å‹
4.  åŸºæœ¬æ­¥éª¤ï¼š1.å•è¯è½¬æ¢æˆå†…åµŒï¼ˆç¼–ç ï¼‰ï¼Œ2.é¢„æµ‹ï¼Œ3.å†…åµŒè¿˜åŸæˆå•è¯ï¼ˆè§£ç ï¼‰ï¼šå†…åµŒçš„ç¼–ç æ˜¯ç«¯åˆ°ç«¯è®­ç»ƒå¾—åˆ°çš„ã€‚

</div>


### [GPT3 ä¸ Transformer](https://jalammar.github.io/how-gpt3-works-visualizations-animations/) {#gpt3-ä¸-transformer}

{{< figure src="/ox-hugo/07-gpt3-processing-transformer-blocks.gif" alt="Overview" title="overview" width="500pix" >}}

{{< figure src="/ox-hugo/08-gpt3-tokens-transformer-blocks.gif" alt="training" title="Training" width="500pix" >}}

{{< figure src="/ox-hugo/09-gpt3-generating-react-code-example.gif" alt="training samples" title="training samples" width="500pix" >}}

{{< figure src="/ox-hugo/10-gpt3-fine-tuning.gif" title="éšç©ºé—´èšç±»åˆ†å¸ƒ" width="500pix" >}}

<div class="NOTES">

1.  96 ä¸ª transformer è§£ç å±‚ï¼Œ æ¯ä¸ªè§£ç å±‚å‚æ•°~1.8B
2.  è§£ç è¿‡ç¨‹
3.  App React ä»£ç ç”Ÿæˆ
4.  è¿ç§»å­¦ä¹ ï¼ˆç‰¹æ®Šä»»åŠ¡çš„ç»†è°ƒï¼‰ï¼š InstructGPT, ChatGPT

<https://twitter.com/i/status/1284421499915403264>

</div>


### ChatGPT {#chatgpt}

{{< figure src="/ox-hugo/ChatGPT_Diagram.svg" title="éšç©ºé—´èšç±»åˆ†å¸ƒ" width="800pix" >}}

-   GPT3.5: codex
-   ç›‘ç£å­¦ä¹ ï¼Œç»†è°ƒ
-   å¼ºåŒ–å­¦ä¹ (PPO)æ„é€ å¥–åŠ±å‡½æ•°
-   åº”ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ”¹è¿›æ¨¡å‹

<div class="NOTES">

-   ä»£ç æ˜¯é«˜è´¨é‡çš„è¯­è¨€
-   è‹±è¯­æ˜¯ä¸€ç§ä¸¥æ ¼çš„å½¢å¼åŒ–è¯­è¨€ï¼ˆè’™å¡”å°¤ï¼‰
-   æ±‰è¯­ï¼šå›¾å½¢åŒ–æ–‡å­—ï¼Œè¯­éŸ³ä¸Šå¤šæ ·æ€§ä¸å¤Ÿï¼Œå¤šéŸ³å­—ï¼ŒåŒéŸ³å­—ï¼Œä¸¥é‡ä¾èµ–ä¸Šä¸‹æ–‡ã€‚å›¾åƒæ€§çš„ä¼˜åŠ¿ï¼Œè¯­éŸ³ä¸Šçš„ç¼ºé™·ï¼Œè¯­ä¹‰ä¸Šè¡¨è¾¾ä¸Šæœ‰ä¸€å®šçš„æ¨¡ç³Šæ€§ï¼Œä¼¼æ˜¯è€Œéã€‚è°éŸ³ã€‚
-   æ±‰è¯­æ ·æœ¬è®­ç»ƒï¼ˆä¸ºè¾…ï¼‰
-   ä¹”å§†æ–¯åŸºï¼šæ™®éè¯­æ³•è®º,èƒ½å­¦ä¼šå¤–è¯­ï¼Œç¿»è¯‘çš„æ ¹æœ¬ã€‚
-   Metaï¼Œç¿»è¯‘å¯¹é½ä¸¤ä¸ªå†…åµŒç©ºé—´çš„æ˜ å°„å…³ç³»ã€‚

-   ä¸ºä½•å¼ºåŒ–å­¦ä¹ ï¼Ÿï¼šè§£å†³é•¿æ•ˆå¥–åŠ±é—®é¢˜ã€‚

</div>


#### æ¶Œç°è¡Œä¸ºï¼ˆ[Emergence Behavior](https://www.jasonwei.net/blog/emergence)) {#æ¶Œç°è¡Œä¸º-emergence-behavior}

{{< figure src="/ox-hugo/emergence.gif" title="Emergence Ablities on Benchmarks" width="600px" >}}

{{< figure src="/ox-hugo/emergence_behavior.jpeg" title="Emergence Behavior" width="600px" >}}

<div class="NOTES">

æ¸©åº¦ä½œä¸ºç‰©ç†ç°è±¡ï¼šæ¶²æ€æ°´ï¼Œè’¸æ±½ï¼Œæ°´åˆ†å­åˆ°è¾¾ä¸€å®šé‡çº§æ‰ä¼šå‡ºç°

</div>


### åº”ç”¨å’Œéƒ¨ç½² {#åº”ç”¨å’Œéƒ¨ç½²}

-   æç¤ºå·¥ç¨‹(Prompt Engineering)
-   LLaMA å¤åˆ» GPT (æ–¯å¦ç¦[Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html) 7B, 100$ï¼‰
    -   é€šè¿‡ API æ¯”å¯¹è®­ç»ƒâ¡å•†ä¸šæ¨¡å¼ï¼Ÿ
-   LLaMA (7B) æ ‘è“æ´¾ç§»æ¤ï¼ˆ4GB, 10sec/tokenï¼‰

<div class="NOTES">

æç¤ºå·¥ç¨‹ï¼š
äººè¡¥å……é•¿é€»è¾‘ä¾èµ–é—®é¢˜ï¼Œå¼¥è¡¥ç¥ç»ç½‘ç»œé•¿åºåˆ—ç†è§£é—®é¢˜ï¼ˆ2k åºåˆ—é•¿åº¦ï¼‰ï¼Œ
ä¸äººå·¥æ™ºèƒ½å¯¹è¯ï¼š

-   å‡†ç¡®æè¿°è¾“å…¥éœ€æ±‚
-   åŒ¹é…æ¨¡å‹å¤šæ¨¡æ€

</div>


### å˜å½¢é‡‘åˆšï¼ˆTransformerï¼‰ {#å˜å½¢é‡‘åˆš-transformer}

{{< figure src="/ox-hugo/transformer.png" alt="Transformer and attention" title="Transformer and attention" width="800px" >}}

-   ç»“æ„: å½’çº³åå·®å°‘ï¼Œé€šç”¨æ€§å¥½
    -   æ³¨æ„åŠ›ï¼ˆå†…æ³¨æ„åŠ›ï¼ˆself attention)ï¼Œäº¤å‰æ³¨æ„åŠ›ï¼Œ å¤šå¤´å†…æ³¨æ„åŠ›
    -   MLP,å¤šå±‚æ„ŸçŸ¥æœº
    -   æ®‹å·®ç»“æ„
-   éœ€è¦å¤§é‡çš„è®­ç»ƒæ ·æœ¬
-   ç½‘ç»œå°ºåº¦å’Œæ•°æ®é›†

<div class="NOTES">

ä½ç½®ç¼–ç 
å±‚å½’ä¸€åŒ–
GPT3
è½¯æ³¨æ„åŠ›ï¼Œç¡¬æ³¨æ„åŠ›
å·ç§¯ç½‘çš„æƒé‡ç³»æ•°ç”¨å¦ä¸€ä¸ªç½‘ç»œç”Ÿæˆï¼šäºŒé˜¶ç½‘ç»œ

</div>


### äº‰è®® {#äº‰è®®}


#### [ChatGPT æ˜¯ç°å®çš„æ¨¡ç³Šç‰ˆæœ¬](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) {#chatgpt-æ˜¯ç°å®çš„æ¨¡ç³Šç‰ˆæœ¬}

{{< figure src="/ox-hugo/Chiang.gif" title="blurry web" width="800pix" >}}

ChatGPT æ˜¯ç°å®çš„æ¨¡ç³Šå¤å°

-   ç±»ä¼¼ jpeg å›¾ç‰‡å¯¹åŸå§‹å›¾ç‰‡çš„æœ‰æŸå‹ç¼©
-   ç°å®çš„æè¿°ä¸ç²¾ç¡®ï¼Œé€ æˆè¯­æ–™å’Œä¿¡æ¯çš„å¤±çœŸå’Œæ¨¡ç³Š
-   æ¨¡å‹å¹»è§‰é—®é¢˜ï¼ˆhallucinationï¼‰ï¼Œé€ æˆè¯­æ–™å’Œä¿¡æ¯çš„æ±¡æŸ“
-   æœ‰æŸå‹ç¼©æ˜¾å¾—æ›´æ™ºèƒ½

<div class="NOTES">

ç”Ÿæˆæ¨¡å‹çš„é«˜æ•ˆè¿…é€Ÿæ”¾å¤§æ±¡æŸ“é—®é¢˜
Markus Hutter Prize 2006 æ™ºèƒ½æ˜¯ä¸€ç§å‹ç¼©ï¼Œæ— æŸå‹ç¼©: 1GB wiki --&gt; 115MB

</div>


#### [GPT4 å’Œè¯­è¨€çš„æœªçŸ¥é¢†åŸŸ](https://www.fast.ai/posts/2023-03-20-wittgenstein.html) {#gpt4-å’Œè¯­è¨€çš„æœªçŸ¥é¢†åŸŸ}

â€œå®ƒä»¬(LLM)è¿˜å¯èƒ½å¸¦æ¥æ–°çš„ä¼¦ç†ã€ç¤¾ä¼šå’Œæ–‡åŒ–æŒ‘æˆ˜ï¼Œéœ€è¦è®¤çœŸåæ€å’Œç›‘ç®¡ã€‚ æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨è¿™é¡¹æŠ€æœ¯å°†å–å†³äºæˆ‘ä»¬å¦‚ä½•è®¤è¯†åˆ°å®ƒå¯¹æˆ‘ä»¬è‡ªå·±å’Œä»–äººçš„å½±å“ã€‚

è¯¥æŠ€æœ¯æ˜¯â€œäººå·¥æ™ºèƒ½â€çš„ä¸€ç§å½¢å¼ã€‚ â€œæ™ºèƒ½â€ä¸€è¯æºè‡ª inter-ï¼ˆâ€œä¹‹é—´â€ï¼‰å’Œ legereï¼ˆâ€œé€‰æ‹©ã€æŒ‘é€‰ã€é˜…è¯»â€ï¼‰ã€‚ é‚£ä¹ˆï¼Œæ™ºèƒ½å°±æ˜¯èƒ½å¤Ÿåœ¨äº‹ç‰©ä¹‹é—´åšå‡ºé€‰æ‹©ï¼ŒæŒ‘é€‰å‡ºé‡è¦çš„ä¸œè¥¿ï¼Œé˜…è¯»æ‰€å†™çš„ä¸œè¥¿ã€‚ æ™ºåŠ›ä¸ä»…ä»…æ˜¯æ•°é‡æˆ–è´¨é‡ï¼› å®ƒæ˜¯ä¸€ç§æ´»åŠ¨ã€ä¸€ç§è¿‡ç¨‹ã€ä¸€ç§å®è·µã€‚ è¿™æ˜¯æˆ‘ä»¬ç”¨æ€æƒ³å’Œè¯­è¨€åšçš„äº‹æƒ…ã€‚

ä½†æ˜¯å½“æˆ‘ä»¬è®© GPT4 ä¸ºæˆ‘ä»¬åšè¿™ä»¶äº‹æ—¶ï¼Œæˆ‘ä»¬ä¸æ˜¯åœ¨æ”¾å¼ƒæˆ‘ä»¬çš„æ™ºèƒ½å—ï¼Ÿ éš¾é“æˆ‘ä»¬æ²¡æœ‰æ”¾å¼ƒé€‰æ‹©ã€æŒ‘é€‰ã€é˜…è¯»çš„èƒ½åŠ›å—ï¼Ÿ æˆ‘ä»¬ä¸æ˜¯å˜æˆäº†è¯­è¨€çš„è¢«åŠ¨æ¶ˆè´¹è€…è€Œä¸æ˜¯ä¸»åŠ¨çš„ç”Ÿäº§è€…å—ï¼Ÿâ€

<div class="NOTES">

Jeremy Howard 2023.02.23
[GPT 4 and the Uncharted Territories of Language](https://www.fast.ai/posts/2023-03-20-wittgenstein.html)

â€œThe limits of my language mean the limits of my world.â€ â€” Ludwig Wittgenstein

They could also create new ethical, social, and cultural challenges that require careful reflection and regulation. How we use this technology will depend on how we recognize its implications for ourselves and others.

This technology is a form of â€œArtificial Intelligenceâ€. The word â€œintelligenceâ€ derives from inter- (â€œbetweenâ€) and legere (â€œto choose, pick out, readâ€). To be intelligent, then, is to be able to choose between things, to pick out what matters, to read what is written. Intelligence is not just a quantity or a quality; it is an activity, a process, a practice. It is something that we do with our minds and our words.

But when we let GPT 4 do this for us, are we not abdicating our intelligence? Are we not letting go of our ability to choose, to pick out, to read? Are we not becoming passive consumers of language instead of active producers?

</div>


#### [æ™ºèƒ½ä¸ä¸€è‡´æ€§é—®é¢˜](https://sohl-dickstein.github.io/2023/03/09/coherence.html) {#æ™ºèƒ½ä¸ä¸€è‡´æ€§é—®é¢˜}

{{< figure src="/ox-hugo/int_coh_cartoon_1.png" title="æ™ºèƒ½ä¸æ¡ç†æ€§ï¼ˆcoherence)" >}}


#### è¶Šé«˜çº§çš„æ™ºèƒ½è¶Šæ··ä¹± {#è¶Šé«˜çº§çš„æ™ºèƒ½è¶Šæ··ä¹±}

{{< figure src="/ox-hugo/int_coh_life.png" title="ç”Ÿç‰©æ™ºèƒ½æ¡ç†æ€§" width="800pix" >}}

{{< figure src="/ox-hugo/int_coh_organization.png" title="ç¤¾ä¼šç»„ç»‡çš„æ¡ç†æ€§" width="800pix" >}}


#### ç¥ç»ç½‘ç»œçš„æ¡ç†æ€§ {#ç¥ç»ç½‘ç»œçš„æ¡ç†æ€§}

{{< figure src="/ox-hugo/int_coh_machines.png" title="ç¥ç»ç½‘ç»œçš„æ¡ç†æ€§" width="800pix" >}}


## å±•æœ›å’ŒæŒ‘æˆ˜ {#å±•æœ›å’ŒæŒ‘æˆ˜}

-   æ•ˆç‡ï¼Œå¼€æ”¾ï¼Œå‡ºå¤„ï¼Œæœ‰æ•ˆæ€§ï¼Œåˆæˆ
    -   åŸºäºæ£€ç´¢ï¼ˆæœç´¢ï¼‰çš„è‡ªç„¶è¯­è¨€å¤„ç†
-   å¤§å‹è¯­è¨€æ¨¡å‹çš„â€œæœ€åä¸€å…¬é‡Œâ€
-   ç½‘ç»œç»“æ„ç†è§£
    -   ç»´æŠ¤ï¼Œé«˜æ•ˆæ›´æ–°
-   ç¼ºç‚¹
    -   é•¿æ®µè½
    -   é•¿é€»è¾‘æ¨ç†ï¼ˆchain-of-thought reasoningï¼‰
        ğŸ‘‰ å¼ºåŒ–å­¦ä¹ ï¼Ÿ
    -   è‡ªç„¶è¯­æ–™æ ·æœ¬ç©ºé—´çš„æ±¡æŸ“
