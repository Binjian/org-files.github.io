<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>veos-paper</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" />
</head>
<body>
<div id="content">
<h1 class="title">veos-paper</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org73c8e51">motivation</a></li>
<li><a href="#org912ffed">sota</a></li>
<li><a href="#org39b4f7b">method</a>
<ul>
<li><a href="#org0fdd04d">model</a>
<ul>
<li><a href="#orge3719e9">vehicle dynamic system modeling</a></li>
<li><a href="#orge75a7b8">reinforcement learning model</a></li>
</ul>
</li>
<li><a href="#orga36b5f6">time sequence is important for exact reward</a></li>
<li><a href="#org1f66ef6">data pool with dask and mongodb for easy sampling, storing, indexing, data interface with DataFrame with every timestamps</a></li>
</ul>
</li>
<li><a href="#org1bf54a0">experiment results discussion</a>
<ul>
<li><a href="#orgbb35cd5">ddpg</a></li>
<li><a href="#org95d0e8a">driving style hinted at a common reward of human drive and agent</a></li>
<li><a href="#org1862b8d">rdpg</a></li>
</ul>
</li>
<li><a href="#orgce5e3df">broader impact</a></li>
</ul>
</div>
</div>
<p>
:ID:       f949414e-7ddf-4d0f-b2b0-d27c2644a498
</p>
<p>
<a href="./20210830182658-veos.html">veos</a>
</p>
<div id="outline-container-org73c8e51" class="outline-2">
<h2 id="org73c8e51">motivation</h2>
<div class="outline-text-2" id="text-org73c8e51">
<p>
alex irpan paper post why reinforcement leanring does not work yet in the real world
scaling up model, is not the case
</p>
<ol class="org-ol">
<li>Simulation atari</li>
<li>Carla</li>
<li>server cluster VAC</li>
<li>Bonsai</li>
</ol>

<p>
make some progress, any progress in the application;
</p>


<p>
learning based.
</p>

<p>
driving decision with short horizon has an impact on the overall energy consumption
</p>

<p>
no realtime requirement, based on the scenario, minutes would be sufficient. actuallly the luxuray of seconds updating the nearby rows of torque table.
</p>

<p>
Contextual Information like NLU different scenario, any action is like tokens. &#x2013;&gt; Sequential decision by transformer/RNN
</p>
</div>
</div>


<div id="outline-container-org912ffed" class="outline-2">
<h2 id="org912ffed">sota</h2>
</div>

<div id="outline-container-org39b4f7b" class="outline-2">
<h2 id="org39b4f7b">method</h2>
<div class="outline-text-2" id="text-org39b4f7b">
</div>
<div id="outline-container-org0fdd04d" class="outline-3">
<h3 id="org0fdd04d">model</h3>
<div class="outline-text-3" id="text-org0fdd04d">
</div>
<div id="outline-container-orge3719e9" class="outline-4">
<h4 id="orge3719e9">vehicle dynamic system modeling</h4>
<div class="outline-text-4" id="text-orge3719e9">
</div>
<ul class="org-ul">
<li><a id="orgf4d09f5"></a>general model<br /></li>
</ul>
</div>
<div id="outline-container-orge75a7b8" class="outline-4">
<h4 id="orge75a7b8">reinforcement learning model</h4>
<div class="outline-text-4" id="text-orge75a7b8">
</div>
<ul class="org-ul">
<li><a id="org18f7fca"></a>action model: torque model, translational mixed gaussian model, with speed translation invariance<br />
<div class="outline-text-5" id="text-org18f7fca">
<p>
equation
</p>
</div>
</li>
<li><a id="org4eda060"></a>observation model: state,<br />
<div class="outline-text-5" id="text-org4eda060">
<p>
equation
</p>
</div>
</li>
<li><a id="orgc8a9a34"></a>reward model<br /></li>
<li><a id="org154a4f6"></a>driver model<br /></li>
</ul>
</div>
</div>

<div id="outline-container-orga36b5f6" class="outline-3">
<h3 id="orga36b5f6">time sequence is important for exact reward</h3>
</div>
<div id="outline-container-org1f66ef6" class="outline-3">
<h3 id="org1f66ef6">data pool with dask and mongodb for easy sampling, storing, indexing, data interface with DataFrame with every timestamps</h3>
</div>
</div>

<div id="outline-container-org1bf54a0" class="outline-2">
<h2 id="org1bf54a0">experiment results discussion</h2>
<div class="outline-text-2" id="text-org1bf54a0">
</div>
<div id="outline-container-orgbb35cd5" class="outline-3">
<h3 id="orgbb35cd5">ddpg</h3>
<div class="outline-text-3" id="text-orgbb35cd5">
<p>
short period of attention window
</p>
</div>
</div>
<div id="outline-container-org95d0e8a" class="outline-3">
<h3 id="org95d0e8a">driving style hinted at a common reward of human drive and agent</h3>
</div>

<div id="outline-container-org1862b8d" class="outline-3">
<h3 id="org1862b8d">rdpg</h3>
<div class="outline-text-3" id="text-org1862b8d">
<p>
long episode truncated BPTT long period of attention window
episode management, training selection,
</p>

<p>
RLHF? easy way with empirical distribution no sequential model, first ignore the time sequence, just to look at the difference.
</p>
</div>
</div>
</div>

<div id="outline-container-orgce5e3df" class="outline-2">
<h2 id="orgce5e3df">broader impact</h2>
<div class="outline-text-2" id="text-orgce5e3df">
<p>
federated learning for meta learning,evolving
NAS,
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="creator"><a href="https://www.gnu.org/software/emacs/">Emacs</a> 27.1 (<a href="https://orgmode.org">Org</a> mode 9.3)</p>
</div>
</body>
</html>
