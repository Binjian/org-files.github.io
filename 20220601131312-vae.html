<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>VAE</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">VAE</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org0b48166">Way of VAE</a>
<ul>
<li><a href="#org03cb0b9">maximum likelihood of the data distribution, with latent space of a minimal prior information</a>
<ul>
<li><a href="#org40eede2">KL-divergence is indirect</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org300cbe2">property</a>
<ul>
<li><a href="#org0fe8dda">prioar \(p(z)\) has an impact, Gaussiana as prior has the maximal entropy and thus minimizaion of the prior information.</a></li>
<li><a href="#org19ce7b3">\(p_{\theta}(z|x)\) and \(q_{\phi}(z|x)\) will be finally very simimlar thus can be ignored.</a></li>
<li><a href="#orge1ba4af">encoder part use KL-Divergence, Decoder data maximum likelihood</a></li>
</ul>
</li>
</ul>
</div>
</div>
<p>
:ID:       7e6148de-8bc4-4064-9498-ab69e2b8587e
</p>

<div id="outline-container-org0b48166" class="outline-2">
<h2 id="org0b48166">Way of VAE</h2>
<div class="outline-text-2" id="text-org0b48166">
</div>
<div id="outline-container-org03cb0b9" class="outline-3">
<h3 id="org03cb0b9">maximum likelihood of the data distribution, with latent space of a minimal prior information</h3>
<div class="outline-text-3" id="text-org03cb0b9">
</div>
<div id="outline-container-org40eede2" class="outline-4">
<h4 id="org40eede2">KL-divergence is indirect</h4>
</div>
</div>
</div>
<div id="outline-container-org300cbe2" class="outline-2">
<h2 id="org300cbe2">property</h2>
<div class="outline-text-2" id="text-org300cbe2">
</div>
<div id="outline-container-org0fe8dda" class="outline-3">
<h3 id="org0fe8dda">prioar \(p(z)\) has an impact, Gaussiana as prior has the maximal entropy and thus minimizaion of the prior information.</h3>
</div>
<div id="outline-container-org19ce7b3" class="outline-3">
<h3 id="org19ce7b3">\(p_{\theta}(z|x)\) and \(q_{\phi}(z|x)\) will be finally very simimlar thus can be ignored.</h3>
</div>
<div id="outline-container-orge1ba4af" class="outline-3">
<h3 id="orge1ba4af">encoder part use KL-Divergence, Decoder data maximum likelihood</h3>
<div class="outline-text-3" id="text-orge1ba4af">
<p>
<a href="./20211221093832-gan.html">GAN</a>
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="creator"><a href="https://www.gnu.org/software/emacs/">Emacs</a> 27.1 (<a href="https://orgmode.org">Org</a> mode 9.3)</p>
</div>
</body>
</html>
